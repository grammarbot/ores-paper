In this section, we explain our general approach toward understanding the systemic mechanisms behind Wikipedia's socio-technical problems and how we, as system builders, might hope to have the most positive impact.  It's clear that Wikipedia's problems are systemic, and a system-level solution is not readily apparent. We hope to dig more deeply and think through how Wikipedia functions as a distributed system, how processes, policies, power, and software come together to make Wikipedia happen, and how systemic change might be possible.

\leadin{Wikipedia as a genre ecology}  Unlike traditional mass-scale projects, Wikipedia's structure and processes are not centrally planned.  Wikipedia's system functions as a heterogeneous assemblage of humans, practices, policies, and software.  Wikipedia is an open system, and its processes are dynamic, complex, and non-deterministic.

A theoretical framework that accounts for the totality of factors and their relationships is essential to building a system-level understanding of state and change processes.  Genre ecologies give us such a framework. A genre ecology consists of ``an interrelated group of genres (artifact types and the interpretive habits that have developed around them) used to jointly mediate the activities that allow people to accomplish complex objectives.''\cite{spinuzzi2000genre}. The genre ecology framework arose out of observational research about the way people engaged in collaborative work amend and repurpose existing officially-sanctioned tools (e.g. written documents, technological interfaces) and developed their own unofficial tools to supplement or circumvent these tools to account for practical contingencies and emergent needs. Tracing the relationships among the set of official and unofficial tools used routinely by a community of practice, and the relationships between tool genres and individual human actors, foregrounds issues of distributed agency, interdependency, rule formalization, and power dynamics in sociotechnical systems<ref name="spinuzzi2003tracing" />.

Morgan \& Zachry used genre ecologies to characterize the relationships between Wikipedia's official policies and essays--unofficial rules, best practices, and editing advice documents that are created by editors in order to contextualize, clarify, and contradict policies\cite{morgan2010negotiating}. Their research demonstrated that on Wikipedia, essays and policies not only co-exist, but interact. For example, the ``proper'' interpretation of Wikipedia's official Civility policy\footnote{\url{http://enwp.org/WP:CIVIL}} within a particular context may need to account for the guidance provided in related essays such as ``No Angry Mastodons''\footnote{\url{http://enwp.org/WP:MASTODON}}.

In genre ecology terms, performing the work of enforcing civil behavior on Wikipedia is dynamically and contingently \emph{mediated} by the guidance provided in the official policy and the guidance provided in any related essays, with the unofficial genres providing interpretive flexibility in the application of official rules to local circumstances as well as challenging and re-interpreting official ideologies and objectives.

Algorithmic systems clearly have a role in mediating the policy, values, and rules in social spaces as well\cite{lessig1999code}.  When looking at Wikipedia's articulation work through the genre ecology lens, it is clear that robots mediate the meaning of policies (c.f., Sinebot's enforcement of the signature policy\cite{geiger2011lives}) and human-computation software mediates the way that Wikipedia enacts quality controls (\emph{c.f.}, the Huggle's vision of quality in Wikipedia as separating good from bad\cite{halfaker2014snuggle}).

\leadin{Wikipedia's problems in automated mediation}  Wikipedia has a long-standing historic problem with how quality control is enacted.  In 2006, when Wikipedia was growing exponentially, the volunteers who managed quality control processes were overwhelmed, and they turned to software agents to help make their process more efficient\cite{halfaker2014snuggle}.  The software they developed focused on the problem they perceived as most important--keeping out the bad stuff at all costs. It formalized processes that were previously more flexible and contingent. Embedding their priorities and values in code reified particular quality standards and pushed other forms of quality control and socialization to the margins\cite{halfaker2013rise}.  The result was a sudden decline in the retention of new editors in Wikipedia and a threat to the core values of the project.

Past work has described these problems as systemic and related to dominant shared-understandings embedded in policies, processes, and software agents\cite{halfaker2014snuggle}.  Quality control is a distributed cognition system that emerged based on community needs and volunteer priorities\cite{geiger2010work}.  Where does change come from in such a system, where problematic assumptions have been embedded in the mediation of policy and the design of software for over a decade?  How does deep change take place in a genre ecology?

\leadin{Making change is complicated by the distributed nature}
Since the publication of a seminal report about the declining retention in Wikipedia, knowledge that Wikipedia's quality control practices are problematic and at the heart of a existential problem for the project have become widespread.  Several initiatives intended to improve socialization practices have been started (e.g. the Teahouse and outreach efforts like Inspire Campaigns\cite{morgan2015what}, and have elicited ideas from contributors on the margins of the community).

The process of quality control has remained largely unchanged.  This assemblage of mindsets, policies, practices, and software prioritizes quality/efficiency and does so effectively \cite{geiger2013levee}\cite{halfaker2014snuggle}.  To move beyond the current state of quality control, we need alternatives to the existing mode of seeing and acting within Wikipedia.

While it's tempting to conclude that ''we just need to fix quality control,'' it's not apparent what a better quality control would look like.  How does one cause systemic change in a distributed system like Wikipedia?  Harding and Harraway's concept of \emph{successors}\cite{haraway1988situated}\cite{harding1987feminism} gives us insight into how we might think about the development of new software/process/policy components.  Past work has explored developing a successor view that prioritizes the support of new editors in Wikipedia over the efficiency of quality control\cite{halfaker2014snuggle}\cite{geiger2014successor}, but a single point rarely changes the direction of an entire conversation or the shape of an entire ecology. Change is still elusive.

Given past efforts to improve the situation for newcomers\cite{morgan2013tea} and the general interest among Wikipedia's quality control workers toward improving socialization\cite{halfaker2014snuggle}, we know that there is general interest in balancing quality/efficiency and diversity/welcoming-ness more effectively.  Where are these designers who incorporate this expanded set of values? Â How to we help them bring forward their alternatives?  How do we help them re-mediate Wikipedia's policies and values through their lens?  How do we support the development of more successors.

\leadin{Expanding the margins of the ecology}
Successors come from the margin, They represent non-dominant values and engage in the re-mediation of articulation\cite{mugar2017preserving}.  We believe that history suggests such successors are a primary means to change in an open ecology like Wikipedia.  For anyone looking to enact a new view of quality control into the designs of a software system, there's a high barrier to entry -- the development of a realtime machine prediction model.  Without exception, all of the critical, high efficiency quality control systems that keep Wikipedia clean of vandalism and other damage employ a machine prediction model for highlighting the edits that are most likely to be bad. For example, Huggle\footnote{\url{http://enwp.org/WP:Snuggle}} and STiki\footnote{\url{http://enwp.org/WP:STiki}} use a machine prediction models to highlight likely damaging edits for human reviews.  ClueBot NG\footnote{\url{http://enwp.org/User:ClueBot_NG}} uses a machine prediction model to automatically revert edits that are highly likely to be damaging.  These automated tools and their users work to employ a multi-stage filter that quickly and efficiently addresses vandalism\cite{geiger2013levee}.

Historically, the barrier to entry with regards to participating in the mediation of quality control policy was a deep understanding of machine classification models.  Without this deep understanding, it wasn't possible to enact an alternative view of how quality controls should be, while also accounting for efficiency and the need to scale.  Notably, one of the key interventions in this area that did so was also built by a computer scientist\cite{halfaker2014snuggle}.

The result is a dominance of a certain type of individual, the stereotypical computer scientist, with an eye towards efficiency and with lesser interest in messy human interaction.  This high barrier to entry and peculiar in-group has exacerbated a minimized margin and a supreme dominance of the authority of quality control regimes that were largely developed in 2006, long before the social costs of efficient quality control were understood.

If the openness of this space to the development of successors (the re-mediation of quality control) is limited by a rare literacy, then we have two options for expanding the margins beyond the current authorities: (1) increase general literacy around machine classification techniques or (2) remove the need to deeply understand practical machine learning to develop an effective quality control tool.

Through the development of ORES, we seek to reify the latter.  By deploying a high-availability machine prediction service and engaging in basic outreach efforts, we intend to lower the barriers to the development of successors.  We hope that by opening the margin to alternative visions of what quality control and newcomer socialization in Wikipedia should look like, we also open the doors to participation of alternative views in the genre ecology around quality control.  If we are successful, we will see new conversations about how new types of algorithmic tools affect editing dynamics.
